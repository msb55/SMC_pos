{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "from deslib.static.oracle import Oracle\n",
    "from marianaasouza.sgh import SGH\n",
    "from reference.rlo.rlo import random_linear_oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X81</th>\n",
       "      <th>X82</th>\n",
       "      <th>X83</th>\n",
       "      <th>X84</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0  X1  X2  X3  X4  X5  X6  X7  X8  X9  ...  X76  X77  X78  X79  X80  X81  \\\n",
       "0  33   1   3   2   8   0   5   1   3   7  ...    0    0    0    1    0    0   \n",
       "1  37   1   2   2   8   1   4   1   4   6  ...    0    0    0    1    0    0   \n",
       "2  37   1   2   2   8   0   4   2   4   3  ...    0    0    0    1    0    0   \n",
       "3   9   1   3   3   3   2   3   2   4   5  ...    0    0    0    1    0    0   \n",
       "4  40   1   4   2  10   1   4   1   4   7  ...    0    0    0    1    0    0   \n",
       "\n",
       "   X82  X83  X84  y  \n",
       "0    0    0    0  0  \n",
       "1    0    0    0  0  \n",
       "2    0    0    0  0  \n",
       "3    0    0    0  0  \n",
       "4    0    0    0  0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_train_file = \"ticdata2000.txt\"\n",
    "insurance_test_file = \"ticeval2000.txt\"\n",
    "insurance_test_labels_file = \"tictgts2000.txt\"\n",
    "\n",
    "insurance_train_data = pd.read_csv(\"./databases/insurance-company-benchmark/\" + insurance_train_file, header=None, sep=\"\\t\")\n",
    "insurance_test_data = pd.read_csv(\"./databases/insurance-company-benchmark/\" + insurance_test_file, header=None, sep=\"\\t\")\n",
    "insurance_test_labels_data = pd.read_csv(\"./databases/insurance-company-benchmark/\" + insurance_test_labels_file, header=None, sep=\"\\t\")\n",
    "\n",
    "insurance_test_data = pd.concat([insurance_test_data, insurance_test_labels_data], axis=1, ignore_index=True)\n",
    "insurance_data = pd.concat([insurance_train_data, insurance_test_data], axis=0, ignore_index=True)\n",
    "\n",
    "insurance_n_row, insurance_n_column = insurance_data.shape\n",
    "insurance_columns = [\"X{}\".format(i) for i in range(0, insurance_n_column-1)] + [\"y\"]\n",
    "insurance_data.columns = insurance_columns\n",
    "\n",
    "insurance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(insurance_data[\"y\"], bins=20)\n",
    "plt.title(\"Distribuição das classes #2\")\n",
    "plt.ylabel(\"# de instâncias\")\n",
    "plt.xlabel(\"Classe\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "def run_ensemble_method(X, y, ensemble_name, n_pool=10, kfold=5):\n",
    "    print(\"Running {} ensemble. Pool = {}. K-fold = {}\".format(ensemble_name, n_pool, kfold))\n",
    "    ensemble_method = None\n",
    "    \n",
    "    perceptron = CalibratedClassifierCV(Perceptron(random_state=random_state))\n",
    "    \n",
    "    if ensemble_name == \"Bagging\":\n",
    "        ensemble_method = BaggingClassifier(perceptron, n_estimators=n_pool, n_jobs=-1, verbose=0, \n",
    "                                            random_state=random_state)\n",
    "    elif ensemble_name == \"AdaBoost\":\n",
    "        ensemble_method = AdaBoostClassifier(perceptron, n_estimators=n_pool, random_state=random_state)\n",
    "    elif ensemble_name == \"Random Subspace\":\n",
    "        ensemble_method = BaggingClassifier(perceptron, n_estimators=n_pool, bootstrap=False, max_features=0.5, \n",
    "                                            n_jobs=-1, verbose=0, random_state=random_state)\n",
    "    elif ensemble_name == \"RLO\":\n",
    "        ensemble_method = random_linear_oracle(n_value=n_pool)\n",
    "    elif ensemble_name == \"SGH\":\n",
    "        ensemble_method = SGH()\n",
    "    else:\n",
    "        raise Exception(\"Ensemble method not known.\")\n",
    "    \n",
    "    return evaluate_ensemble_method(X, y, ensemble_method, k_fold=5, is_random_subspace=(ensemble_name == \"Random Subspace\"), is_random_oracles=(ensemble_name == \"RLO\"), is_sgh=(ensemble_name == \"SGH\"), n_pool=n_pool)\n",
    "\n",
    "def evaluate_ensemble_method(X, y, pool_classifiers, k_fold=5, is_random_subspace=False, is_random_oracles=False, is_sgh=False, n_pool=10):\n",
    "    # Scale the variables to have 0 mean and unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(data=X)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=random_state) # criacao dos k_fold estratificados\n",
    "    \n",
    "    oracle_scores = []\n",
    "    index = 0\n",
    "    for train_index, test_index in cv.split(X, list(y.values)): # para cada fold\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index] # separacao entre dados de treinamento e teste\n",
    "        \n",
    "        epoch = {'execution': index}\n",
    "        \n",
    "        start = time.time()\n",
    "        if is_sgh is False and is_random_oracles is False:\n",
    "            pool_classifiers.fit(X_train, y_train.values)\n",
    "        elif is_random_oracles is True:\n",
    "            pool_classifiers = random_linear_oracle(n_value=n_pool)\n",
    "            pool_classifiers.fit(X_train, y_train.values)\n",
    "        elif is_sgh is True:\n",
    "            pool_classifiers = SGH()\n",
    "            pool_classifiers.fit(X_train.values, y_train.values)\n",
    "            epoch['hyperplans_per_classes'] = pool_classifiers.hyperplan_per_class_\n",
    "        end = time.time()        \n",
    "        epoch['ensemble_fit_time'] = (end-start)\n",
    "        \n",
    "        start = time.time()\n",
    "        if is_random_subspace is False and is_random_oracles is False and is_sgh is False:\n",
    "            oracle = Oracle(pool_classifiers, random_state=random_state)\n",
    "            oracle.fit(X_train, y_train.values)\n",
    "            score = oracle.score(X_test, y_test.values)\n",
    "        elif is_random_subspace is True:\n",
    "            score = oracle_for_random_subspace(pool_classifiers, X_test, y_test.values)\n",
    "        elif is_random_oracles is True:\n",
    "            score = pool_classifiers.oracle(X_test, y_test.values)\n",
    "        else:\n",
    "            oracle = Oracle(pool_classifiers, random_state=random_state)\n",
    "            oracle.fit(X_train, y_train.values)\n",
    "            score = oracle.score(X_test, y_test.values)\n",
    "            epoch['predicted'] = list(oracle.predict(X_test, y_test.values))\n",
    "            epoch['expected'] = list(y_test.values)\n",
    "            \n",
    "        end = time.time()\n",
    "        epoch['oracle_fit_time'] = (end-start)\n",
    "        epoch['oracle_score'] = score\n",
    "        \n",
    "        oracle_scores.append(epoch)\n",
    "        \n",
    "        index = index + 1\n",
    "\n",
    "    return oracle_scores\n",
    "\n",
    "def oracle_for_random_subspace(meta_model, X_test, y_test):\n",
    "    base_models = meta_model.estimators_\n",
    "    base_models_feats = meta_model.estimators_features_\n",
    "\n",
    "    base_models_preds = []\n",
    "    for i in range(len(base_models)):\n",
    "        X_test_subspace = X_test.iloc[:,base_models_feats[i]] #selecting only the columns used for the ith base model.\n",
    "        y_pred = base_models[i].predict(X_test_subspace)\n",
    "        base_models_preds.append(y_pred)\n",
    "\n",
    "    oracle_hits = []\n",
    "    for i in range(len(y_test)):\n",
    "        oracle_hit = 0\n",
    "        for j in range(len(base_models_preds)):\n",
    "            if base_models_preds[j][i] == y_test[i]:\n",
    "                oracle_hit = 1\n",
    "                break\n",
    "        oracle_hits.append(oracle_hit)\n",
    "\n",
    "    oracle_score = np.sum(oracle_hits)/len(oracle_hits)\n",
    "    return oracle_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pools = [i for i in range(10, 110, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bagging ensemble. Pool = 10. K-fold = 5\n",
      "Ensemble fit time: 1.25s\n",
      "Oracle time: 1.80s\n",
      "Ensemble fit time: 0.28s\n",
      "Oracle time: 2.04s\n",
      "Ensemble fit time: 0.72s\n",
      "Oracle time: 2.35s\n",
      "Ensemble fit time: 0.93s\n",
      "Oracle time: 2.41s\n",
      "Ensemble fit time: 0.40s\n",
      "Oracle time: 1.80s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.2452809810638428, 'oracle_fit_time': 1.7954058647155762, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.2760612964630127, 'oracle_fit_time': 2.0384633541107178, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.7231624126434326, 'oracle_fit_time': 2.347531795501709, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.9272072315216064, 'oracle_fit_time': 2.4105429649353027, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.4010889530181885, 'oracle_fit_time': 1.802912950515747, 'oracle_score': 0.9404276985743381}]\n",
      "Running Bagging ensemble. Pool = 20. K-fold = 5\n",
      "Ensemble fit time: 0.48s\n",
      "Oracle time: 2.90s\n",
      "Ensemble fit time: 1.74s\n",
      "Oracle time: 3.17s\n",
      "Ensemble fit time: 0.69s\n",
      "Oracle time: 2.41s\n",
      "Ensemble fit time: 0.43s\n",
      "Oracle time: 2.34s\n",
      "Ensemble fit time: 0.45s\n",
      "Oracle time: 2.41s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.4846184253692627, 'oracle_fit_time': 2.896655559539795, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 1.7403934001922607, 'oracle_fit_time': 3.1667144298553467, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.6891553401947021, 'oracle_fit_time': 2.4075443744659424, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.430095911026001, 'oracle_fit_time': 2.342538595199585, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.4501004219055176, 'oracle_fit_time': 2.406543493270874, 'oracle_score': 0.9404276985743381}]\n",
      "Running Bagging ensemble. Pool = 30. K-fold = 5\n",
      "Ensemble fit time: 0.77s\n",
      "Oracle time: 4.17s\n",
      "Ensemble fit time: 1.80s\n",
      "Oracle time: 3.44s\n",
      "Ensemble fit time: 0.61s\n",
      "Oracle time: 2.98s\n",
      "Ensemble fit time: 0.57s\n",
      "Oracle time: 4.13s\n",
      "Ensemble fit time: 2.10s\n",
      "Oracle time: 4.10s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.7691760063171387, 'oracle_fit_time': 4.174943447113037, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 1.8044054508209229, 'oracle_fit_time': 3.4367761611938477, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 0.6081380844116211, 'oracle_fit_time': 2.983682870864868, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.573129415512085, 'oracle_fit_time': 4.13093376159668, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 2.1004750728607178, 'oracle_fit_time': 4.095923900604248, 'oracle_score': 0.9404276985743381}]\n",
      "Running Bagging ensemble. Pool = 40. K-fold = 5\n",
      "Ensemble fit time: 1.03s\n",
      "Oracle time: 3.68s\n",
      "Ensemble fit time: 0.75s\n",
      "Oracle time: 3.69s\n",
      "Ensemble fit time: 0.74s\n",
      "Oracle time: 4.21s\n",
      "Ensemble fit time: 2.39s\n",
      "Oracle time: 4.98s\n",
      "Ensemble fit time: 1.79s\n",
      "Oracle time: 3.71s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.0302329063415527, 'oracle_fit_time': 3.677335023880005, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 0.7511687278747559, 'oracle_fit_time': 3.6878421306610107, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 0.7411668300628662, 'oracle_fit_time': 4.20845890045166, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 2.3855397701263428, 'oracle_fit_time': 4.984126806259155, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 1.7874045372009277, 'oracle_fit_time': 3.7094955444335938, 'oracle_score': 0.9404276985743381}]\n",
      "Running Bagging ensemble. Pool = 50. K-fold = 5\n",
      "Ensemble fit time: 0.95s\n",
      "Oracle time: 5.86s\n",
      "Ensemble fit time: 2.81s\n",
      "Oracle time: 4.94s\n",
      "Ensemble fit time: 0.90s\n",
      "Oracle time: 6.09s\n",
      "Ensemble fit time: 3.24s\n",
      "Oracle time: 4.65s\n",
      "Ensemble fit time: 0.95s\n",
      "Oracle time: 4.29s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.9504199028015137, 'oracle_fit_time': 5.857011079788208, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 2.8051772117614746, 'oracle_fit_time': 4.937660455703735, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 0.901498556137085, 'oracle_fit_time': 6.087996244430542, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 3.2447597980499268, 'oracle_fit_time': 4.648334264755249, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 0.94622802734375, 'oracle_fit_time': 4.292979001998901, 'oracle_score': 0.9404276985743381}]\n",
      "Running Bagging ensemble. Pool = 60. K-fold = 5\n",
      "Ensemble fit time: 1.02s\n",
      "Oracle time: 7.38s\n",
      "Ensemble fit time: 2.37s\n",
      "Oracle time: 5.00s\n",
      "Ensemble fit time: 1.04s\n",
      "Oracle time: 6.42s\n",
      "Ensemble fit time: 3.28s\n",
      "Oracle time: 6.39s\n",
      "Ensemble fit time: 0.97s\n",
      "Oracle time: 5.04s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.0182225704193115, 'oracle_fit_time': 7.37766695022583, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 2.367532730102539, 'oracle_fit_time': 4.999138355255127, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 1.0352332592010498, 'oracle_fit_time': 6.423961877822876, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 3.284742832183838, 'oracle_fit_time': 6.394442558288574, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 0.9732186794281006, 'oracle_fit_time': 5.039138317108154, 'oracle_score': 0.9409368635437881}]\n",
      "Running Bagging ensemble. Pool = 70. K-fold = 5\n",
      "Ensemble fit time: 1.24s\n",
      "Oracle time: 5.57s\n",
      "Ensemble fit time: 2.18s\n",
      "Oracle time: 7.88s\n",
      "Ensemble fit time: 3.41s\n",
      "Oracle time: 5.61s\n",
      "Ensemble fit time: 1.14s\n",
      "Oracle time: 7.93s\n",
      "Ensemble fit time: 3.98s\n",
      "Oracle time: 6.00s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.2382795810699463, 'oracle_fit_time': 5.567257404327393, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 2.1794934272766113, 'oracle_fit_time': 7.878779411315918, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 3.4077675342559814, 'oracle_fit_time': 5.613275051116943, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 1.138256311416626, 'oracle_fit_time': 7.933792591094971, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 3.9829018115997314, 'oracle_fit_time': 5.995858669281006, 'oracle_score': 0.9409368635437881}]\n",
      "Running Bagging ensemble. Pool = 80. K-fold = 5\n",
      "Ensemble fit time: 4.26s\n",
      "Oracle time: 8.19s\n",
      "Ensemble fit time: 1.54s\n",
      "Oracle time: 6.25s\n",
      "Ensemble fit time: 1.37s\n",
      "Oracle time: 8.08s\n",
      "Ensemble fit time: 4.27s\n",
      "Oracle time: 6.83s\n",
      "Ensemble fit time: 1.30s\n",
      "Oracle time: 7.70s\n",
      "[{'execution': 0, 'ensemble_fit_time': 4.264963865280151, 'oracle_fit_time': 8.185356616973877, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 1.535240650177002, 'oracle_fit_time': 6.250936031341553, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 1.3743102550506592, 'oracle_fit_time': 8.081333637237549, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 4.266960144042969, 'oracle_fit_time': 6.830542325973511, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 1.296292781829834, 'oracle_fit_time': 7.702742576599121, 'oracle_score': 0.9409368635437881}]\n",
      "Running Bagging ensemble. Pool = 90. K-fold = 5\n",
      "Ensemble fit time: 4.54s\n",
      "Oracle time: 8.74s\n",
      "Ensemble fit time: 1.44s\n",
      "Oracle time: 6.94s\n",
      "Ensemble fit time: 1.44s\n",
      "Oracle time: 8.28s\n",
      "Ensemble fit time: 4.44s\n",
      "Oracle time: 8.61s\n",
      "Ensemble fit time: 1.44s\n",
      "Oracle time: 8.28s\n",
      "[{'execution': 0, 'ensemble_fit_time': 4.538024663925171, 'oracle_fit_time': 8.74347734451294, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 1.4403252601623535, 'oracle_fit_time': 6.941605806350708, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 1.4443254470825195, 'oracle_fit_time': 8.277871131896973, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 4.441003322601318, 'oracle_fit_time': 8.614450454711914, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 1.4393243789672852, 'oracle_fit_time': 8.284398078918457, 'oracle_score': 0.9409368635437881}]\n",
      "Running Bagging ensemble. Pool = 100. K-fold = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble fit time: 4.80s\n",
      "Oracle time: 8.93s\n",
      "Ensemble fit time: 5.33s\n",
      "Oracle time: 10.47s\n",
      "Ensemble fit time: 1.63s\n",
      "Oracle time: 7.54s\n",
      "Ensemble fit time: 1.53s\n",
      "Oracle time: 10.23s\n",
      "Ensemble fit time: 5.38s\n",
      "Oracle time: 7.50s\n",
      "[{'execution': 0, 'ensemble_fit_time': 4.804086208343506, 'oracle_fit_time': 8.927027702331543, 'oracle_score': 0.9409669211195929}, {'execution': 1, 'ensemble_fit_time': 5.326203346252441, 'oracle_fit_time': 10.471874952316284, 'oracle_score': 0.9404580152671755}, {'execution': 2, 'ensemble_fit_time': 1.6323683261871338, 'oracle_fit_time': 7.541760444641113, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 1.526336431503296, 'oracle_fit_time': 10.229825496673584, 'oracle_score': 0.9409368635437881}, {'execution': 4, 'ensemble_fit_time': 5.3772125244140625, 'oracle_fit_time': 7.500227928161621, 'oracle_score': 0.9409368635437881}]\n"
     ]
    }
   ],
   "source": [
    "X_insurance = insurance_data.iloc[:,0:len(insurance_columns)-1] # separacao de atributos\n",
    "y_insurance = insurance_data.iloc[:,len(insurance_columns)-1] # separacao de classes\n",
    "\n",
    "insurance_score = {}\n",
    "ensemble_method = \"Bagging\"\n",
    "insurance_score[ensemble_method] = {}\n",
    "for n_pool in n_pools:\n",
    "    result = run_ensemble_method(X_insurance, y_insurance, ensemble_method, n_pool, 5)\n",
    "    print(result)\n",
    "    insurance_score[ensemble_method][str(n_pool)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost ensemble. Pool = 10. K-fold = 5\n",
      "Ensemble fit time: 0.72s\n",
      "Oracle time: 1.72s\n",
      "Ensemble fit time: 1.99s\n",
      "Oracle time: 1.72s\n",
      "Ensemble fit time: 2.06s\n",
      "Oracle time: 1.77s\n",
      "Ensemble fit time: 1.88s\n",
      "Oracle time: 1.73s\n",
      "Ensemble fit time: 1.91s\n",
      "Oracle time: 1.75s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.7151625156402588, 'oracle_fit_time': 1.7173900604248047, 'oracle_score': 0.9979643765903308}, {'execution': 1, 'ensemble_fit_time': 1.989961862564087, 'oracle_fit_time': 1.7213895320892334, 'oracle_score': 0.9979643765903308}, {'execution': 2, 'ensemble_fit_time': 2.0634679794311523, 'oracle_fit_time': 1.7723991870880127, 'oracle_score': 0.9989816700610998}, {'execution': 3, 'ensemble_fit_time': 1.8774240016937256, 'oracle_fit_time': 1.7343933582305908, 'oracle_score': 0.9989816700610998}, {'execution': 4, 'ensemble_fit_time': 1.9054300785064697, 'oracle_fit_time': 1.7513926029205322, 'oracle_score': 0.9989816700610998}]\n",
      "Running AdaBoost ensemble. Pool = 20. K-fold = 5\n",
      "Ensemble fit time: 1.98s\n",
      "Oracle time: 1.27s\n",
      "Ensemble fit time: 1.43s\n",
      "Oracle time: 1.28s\n",
      "Ensemble fit time: 1.46s\n",
      "Oracle time: 1.32s\n",
      "Ensemble fit time: 1.46s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 1.42s\n",
      "Oracle time: 1.35s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.9754457473754883, 'oracle_fit_time': 1.2732875347137451, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 1.433323621749878, 'oracle_fit_time': 1.2822980880737305, 'oracle_score': 0.9994910941475827}, {'execution': 2, 'ensemble_fit_time': 1.457329273223877, 'oracle_fit_time': 1.3212976455688477, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 1.456836462020874, 'oracle_fit_time': 1.331300973892212, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 1.4188258647918701, 'oracle_fit_time': 1.3523051738739014, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 30. K-fold = 5\n",
      "Ensemble fit time: 2.15s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 5.56s\n",
      "Oracle time: 1.69s\n",
      "Ensemble fit time: 5.80s\n",
      "Oracle time: 1.75s\n",
      "Ensemble fit time: 3.73s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 2.15s\n",
      "Oracle time: 1.35s\n",
      "[{'execution': 0, 'ensemble_fit_time': 2.151994466781616, 'oracle_fit_time': 1.3302984237670898, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 5.560767412185669, 'oracle_fit_time': 1.6893815994262695, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 5.796311855316162, 'oracle_fit_time': 1.7543954849243164, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 3.728839635848999, 'oracle_fit_time': 1.3323004245758057, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 2.145991086959839, 'oracle_fit_time': 1.3503046035766602, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 40. K-fold = 5\n",
      "Ensemble fit time: 7.38s\n",
      "Oracle time: 1.75s\n",
      "Ensemble fit time: 7.80s\n",
      "Oracle time: 1.50s\n",
      "Ensemble fit time: 2.91s\n",
      "Oracle time: 1.62s\n",
      "Ensemble fit time: 7.65s\n",
      "Oracle time: 1.74s\n",
      "Ensemble fit time: 6.91s\n",
      "Oracle time: 1.31s\n",
      "[{'execution': 0, 'ensemble_fit_time': 7.382245302200317, 'oracle_fit_time': 1.7494359016418457, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 7.800829887390137, 'oracle_fit_time': 1.5043375492095947, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 2.9096744060516357, 'oracle_fit_time': 1.6173663139343262, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 7.647751092910767, 'oracle_fit_time': 1.7363920211791992, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 6.912559509277344, 'oracle_fit_time': 1.3133065700531006, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 50. K-fold = 5\n",
      "Ensemble fit time: 3.63s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 3.68s\n",
      "Oracle time: 1.49s\n",
      "Ensemble fit time: 9.63s\n",
      "Oracle time: 1.71s\n",
      "Ensemble fit time: 6.53s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 3.62s\n",
      "Oracle time: 1.35s\n",
      "[{'execution': 0, 'ensemble_fit_time': 3.626315116882324, 'oracle_fit_time': 1.3292994499206543, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 3.675830841064453, 'oracle_fit_time': 1.4853358268737793, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 9.632174491882324, 'oracle_fit_time': 1.71138596534729, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 6.53498387336731, 'oracle_fit_time': 1.3332993984222412, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 3.6238183975219727, 'oracle_fit_time': 1.3473029136657715, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 60. K-fold = 5\n",
      "Ensemble fit time: 10.30s\n",
      "Oracle time: 1.82s\n",
      "Ensemble fit time: 9.88s\n",
      "Oracle time: 1.35s\n",
      "Ensemble fit time: 4.37s\n",
      "Oracle time: 1.32s\n",
      "Ensemble fit time: 4.41s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 4.38s\n",
      "Oracle time: 1.34s\n",
      "[{'execution': 0, 'ensemble_fit_time': 10.29832935333252, 'oracle_fit_time': 1.8214118480682373, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 9.88323163986206, 'oracle_fit_time': 1.3543052673339844, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 4.372494697570801, 'oracle_fit_time': 1.3182969093322754, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 4.411499738693237, 'oracle_fit_time': 1.3272995948791504, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 4.382492780685425, 'oracle_fit_time': 1.3433032035827637, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 70. K-fold = 5\n",
      "Ensemble fit time: 14.10s\n",
      "Oracle time: 1.80s\n",
      "Ensemble fit time: 7.51s\n",
      "Oracle time: 1.33s\n",
      "Ensemble fit time: 10.32s\n",
      "Oracle time: 1.90s\n",
      "Ensemble fit time: 10.98s\n",
      "Oracle time: 1.35s\n",
      "Ensemble fit time: 11.26s\n",
      "Oracle time: 1.76s\n",
      "[{'execution': 0, 'ensemble_fit_time': 14.095198392868042, 'oracle_fit_time': 1.7994060516357422, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 7.510695695877075, 'oracle_fit_time': 1.3343007564544678, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 10.319330930709839, 'oracle_fit_time': 1.8984291553497314, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 10.981990098953247, 'oracle_fit_time': 1.3523056507110596, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 11.257545471191406, 'oracle_fit_time': 1.7573978900909424, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 80. K-fold = 5\n",
      "Ensemble fit time: 10.84s\n",
      "Oracle time: 1.34s\n",
      "Ensemble fit time: 5.98s\n",
      "Oracle time: 1.31s\n",
      "Ensemble fit time: 14.77s\n",
      "Oracle time: 1.70s\n",
      "Ensemble fit time: 7.87s\n",
      "Oracle time: 1.32s\n",
      "Ensemble fit time: 8.67s\n",
      "Oracle time: 1.87s\n",
      "[{'execution': 0, 'ensemble_fit_time': 10.843873977661133, 'oracle_fit_time': 1.3413019180297852, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 5.982856273651123, 'oracle_fit_time': 1.3132972717285156, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 14.774336099624634, 'oracle_fit_time': 1.7043869495391846, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 7.865785837173462, 'oracle_fit_time': 1.3182976245880127, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 8.667463541030884, 'oracle_fit_time': 1.8664188385009766, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 90. K-fold = 5\n",
      "Ensemble fit time: 16.55s\n",
      "Oracle time: 1.31s\n",
      "Ensemble fit time: 6.86s\n",
      "Oracle time: 1.31s\n",
      "Ensemble fit time: 6.74s\n",
      "Oracle time: 1.31s\n",
      "Ensemble fit time: 11.81s\n",
      "Oracle time: 1.79s\n",
      "Ensemble fit time: 14.02s\n",
      "Oracle time: 1.29s\n",
      "[{'execution': 0, 'ensemble_fit_time': 16.550246715545654, 'oracle_fit_time': 1.3137993812561035, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 6.863057851791382, 'oracle_fit_time': 1.3067989349365234, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 6.736521005630493, 'oracle_fit_time': 1.308295488357544, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 11.80728554725647, 'oracle_fit_time': 1.7854020595550537, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 14.022167921066284, 'oracle_fit_time': 1.2943024635314941, 'oracle_score': 1.0}]\n",
      "Running AdaBoost ensemble. Pool = 100. K-fold = 5\n",
      "Ensemble fit time: 12.52s\n",
      "Oracle time: 1.73s\n",
      "Ensemble fit time: 15.12s\n",
      "Oracle time: 1.32s\n",
      "Ensemble fit time: 19.24s\n",
      "Oracle time: 1.72s\n",
      "Ensemble fit time: 8.14s\n",
      "Oracle time: 1.28s\n",
      "Ensemble fit time: 11.57s\n",
      "Oracle time: 1.76s\n",
      "[{'execution': 0, 'ensemble_fit_time': 12.522820711135864, 'oracle_fit_time': 1.7253923416137695, 'oracle_score': 1.0}, {'execution': 1, 'ensemble_fit_time': 15.119425773620605, 'oracle_fit_time': 1.3182976245880127, 'oracle_score': 1.0}, {'execution': 2, 'ensemble_fit_time': 19.240347385406494, 'oracle_fit_time': 1.7153866291046143, 'oracle_score': 1.0}, {'execution': 3, 'ensemble_fit_time': 8.142348051071167, 'oracle_fit_time': 1.2772972583770752, 'oracle_score': 1.0}, {'execution': 4, 'ensemble_fit_time': 11.57263445854187, 'oracle_fit_time': 1.7583973407745361, 'oracle_score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "ensemble_method = \"AdaBoost\"\n",
    "insurance_score[ensemble_method] = {}\n",
    "for n_pool in n_pools:\n",
    "    result = run_ensemble_method(X_insurance, y_insurance, ensemble_method, n_pool, 5)\n",
    "    print(result)\n",
    "    insurance_score[ensemble_method][str(n_pool)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Random Subspace ensemble. Pool = 10. K-fold = 5\n",
      "Ensemble fit time: 2.94s\n",
      "Oracle time: 0.05s\n",
      "Ensemble fit time: 0.35s\n",
      "Oracle time: 0.05s\n",
      "Ensemble fit time: 0.33s\n",
      "Oracle time: 0.05s\n",
      "Ensemble fit time: 0.32s\n",
      "Oracle time: 0.05s\n",
      "Ensemble fit time: 0.35s\n",
      "Oracle time: 0.04s\n",
      "[{'execution': 0, 'ensemble_fit_time': 2.942664861679077, 'oracle_fit_time': 0.0510106086730957, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.35107922554016113, 'oracle_fit_time': 0.049008846282958984, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.33007335662841797, 'oracle_fit_time': 0.045011281967163086, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.31707239151000977, 'oracle_fit_time': 0.047010183334350586, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.3540804386138916, 'oracle_fit_time': 0.04400944709777832, 'oracle_score': 0.9404276985743381}]\n",
      "Running Random Subspace ensemble. Pool = 20. K-fold = 5\n",
      "Ensemble fit time: 0.57s\n",
      "Oracle time: 0.09s\n",
      "Ensemble fit time: 1.14s\n",
      "Oracle time: 0.09s\n",
      "Ensemble fit time: 1.29s\n",
      "Oracle time: 0.09s\n",
      "Ensemble fit time: 0.59s\n",
      "Oracle time: 0.09s\n",
      "Ensemble fit time: 0.51s\n",
      "Oracle time: 0.09s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.5741310119628906, 'oracle_fit_time': 0.09301900863647461, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 1.1392579078674316, 'oracle_fit_time': 0.09002089500427246, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 1.287290334701538, 'oracle_fit_time': 0.08701968193054199, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.5911355018615723, 'oracle_fit_time': 0.08601999282836914, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.5061147212982178, 'oracle_fit_time': 0.0870201587677002, 'oracle_score': 0.9404276985743381}]\n",
      "Running Random Subspace ensemble. Pool = 30. K-fold = 5\n",
      "Ensemble fit time: 0.66s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.65s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.65s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.67s\n",
      "Oracle time: 0.13s\n",
      "Ensemble fit time: 0.62s\n",
      "Oracle time: 0.14s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.663149356842041, 'oracle_fit_time': 0.1400313377380371, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.6461465358734131, 'oracle_fit_time': 0.14103198051452637, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.6541457176208496, 'oracle_fit_time': 0.1430339813232422, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.6651492118835449, 'oracle_fit_time': 0.1340315341949463, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.6161398887634277, 'oracle_fit_time': 0.14403176307678223, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 40. K-fold = 5\n",
      "Ensemble fit time: 0.66s\n",
      "Oracle time: 0.17s\n",
      "Ensemble fit time: 0.64s\n",
      "Oracle time: 0.16s\n",
      "Ensemble fit time: 0.63s\n",
      "Oracle time: 0.13s\n",
      "Ensemble fit time: 0.63s\n",
      "Oracle time: 0.11s\n",
      "Ensemble fit time: 0.61s\n",
      "Oracle time: 0.10s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.6631512641906738, 'oracle_fit_time': 0.16803669929504395, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.6441442966461182, 'oracle_fit_time': 0.1560354232788086, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.6341419219970703, 'oracle_fit_time': 0.13002991676330566, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.6301407814025879, 'oracle_fit_time': 0.10502338409423828, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.6051304340362549, 'oracle_fit_time': 0.0960226058959961, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 50. K-fold = 5\n",
      "Ensemble fit time: 0.64s\n",
      "Oracle time: 0.12s\n",
      "Ensemble fit time: 0.54s\n",
      "Oracle time: 0.12s\n",
      "Ensemble fit time: 0.60s\n",
      "Oracle time: 0.12s\n",
      "Ensemble fit time: 0.52s\n",
      "Oracle time: 0.12s\n",
      "Ensemble fit time: 0.54s\n",
      "Oracle time: 0.12s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.6431457996368408, 'oracle_fit_time': 0.12302803993225098, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.5421218872070312, 'oracle_fit_time': 0.12202739715576172, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.5951333045959473, 'oracle_fit_time': 0.12002730369567871, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.51511549949646, 'oracle_fit_time': 0.11902689933776855, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.5421223640441895, 'oracle_fit_time': 0.11902713775634766, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 60. K-fold = 5\n",
      "Ensemble fit time: 0.61s\n",
      "Oracle time: 0.15s\n",
      "Ensemble fit time: 0.63s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.59s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.67s\n",
      "Oracle time: 0.14s\n",
      "Ensemble fit time: 0.62s\n",
      "Oracle time: 0.14s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.6101377010345459, 'oracle_fit_time': 0.1450331211090088, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.6301412582397461, 'oracle_fit_time': 0.14403247833251953, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.5891320705413818, 'oracle_fit_time': 0.14203166961669922, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.666149377822876, 'oracle_fit_time': 0.14403247833251953, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.6211388111114502, 'oracle_fit_time': 0.14203214645385742, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 70. K-fold = 5\n",
      "Ensemble fit time: 0.72s\n",
      "Oracle time: 0.17s\n",
      "Ensemble fit time: 0.71s\n",
      "Oracle time: 0.17s\n",
      "Ensemble fit time: 0.71s\n",
      "Oracle time: 0.17s\n",
      "Ensemble fit time: 0.71s\n",
      "Oracle time: 0.17s\n",
      "Ensemble fit time: 0.71s\n",
      "Oracle time: 0.17s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.7171618938446045, 'oracle_fit_time': 0.16803812980651855, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.7071583271026611, 'oracle_fit_time': 0.16803812980651855, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 0.7091588973999023, 'oracle_fit_time': 0.1670377254486084, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.7111601829528809, 'oracle_fit_time': 0.16803812980651855, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 0.7071590423583984, 'oracle_fit_time': 0.16803812980651855, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 80. K-fold = 5\n",
      "Ensemble fit time: 0.78s\n",
      "Oracle time: 0.20s\n",
      "Ensemble fit time: 0.93s\n",
      "Oracle time: 0.39s\n",
      "Ensemble fit time: 1.14s\n",
      "Oracle time: 0.40s\n",
      "Ensemble fit time: 0.94s\n",
      "Oracle time: 0.38s\n",
      "Ensemble fit time: 1.03s\n",
      "Oracle time: 0.38s\n",
      "[{'execution': 0, 'ensemble_fit_time': 0.7822074890136719, 'oracle_fit_time': 0.20001506805419922, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 0.932213306427002, 'oracle_fit_time': 0.38608646392822266, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 1.1352577209472656, 'oracle_fit_time': 0.3980906009674072, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 0.9352114200592041, 'oracle_fit_time': 0.3760831356048584, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 1.0252327919006348, 'oracle_fit_time': 0.3800845146179199, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 90. K-fold = 5\n",
      "Ensemble fit time: 1.20s\n",
      "Oracle time: 0.43s\n",
      "Ensemble fit time: 1.10s\n",
      "Oracle time: 0.44s\n",
      "Ensemble fit time: 1.04s\n",
      "Oracle time: 0.45s\n",
      "Ensemble fit time: 1.34s\n",
      "Oracle time: 0.44s\n",
      "Ensemble fit time: 1.16s\n",
      "Oracle time: 0.44s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.2042722702026367, 'oracle_fit_time': 0.42609691619873047, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 1.1012496948242188, 'oracle_fit_time': 0.4391002655029297, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 1.0442345142364502, 'oracle_fit_time': 0.45110249519348145, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 1.3373022079467773, 'oracle_fit_time': 0.43709826469421387, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 1.1572625637054443, 'oracle_fit_time': 0.43709611892700195, 'oracle_score': 0.9409368635437881}]\n",
      "Running Random Subspace ensemble. Pool = 100. K-fold = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble fit time: 1.07s\n",
      "Oracle time: 0.49s\n",
      "Ensemble fit time: 1.22s\n",
      "Oracle time: 0.49s\n",
      "Ensemble fit time: 1.30s\n",
      "Oracle time: 0.46s\n",
      "Ensemble fit time: 1.27s\n",
      "Oracle time: 0.49s\n",
      "Ensemble fit time: 1.27s\n",
      "Oracle time: 0.49s\n",
      "[{'execution': 0, 'ensemble_fit_time': 1.0732421875, 'oracle_fit_time': 0.4921116828918457, 'oracle_score': 0.9404580152671755}, {'execution': 1, 'ensemble_fit_time': 1.2202744483947754, 'oracle_fit_time': 0.4871096611022949, 'oracle_score': 0.9399491094147583}, {'execution': 2, 'ensemble_fit_time': 1.3022940158843994, 'oracle_fit_time': 0.4561014175415039, 'oracle_score': 0.9404276985743381}, {'execution': 3, 'ensemble_fit_time': 1.2702877521514893, 'oracle_fit_time': 0.4851083755493164, 'oracle_score': 0.9404276985743381}, {'execution': 4, 'ensemble_fit_time': 1.2662878036499023, 'oracle_fit_time': 0.4941108226776123, 'oracle_score': 0.9409368635437881}]\n"
     ]
    }
   ],
   "source": [
    "ensemble_method = \"Random Subspace\"\n",
    "insurance_score[ensemble_method] = {}\n",
    "for n_pool in n_pools:\n",
    "    result = run_ensemble_method(X_insurance, y_insurance, ensemble_method, n_pool, 5)\n",
    "    print(result)\n",
    "    insurance_score[ensemble_method][str(n_pool)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RLO ensemble. Pool = 10. K-fold = 5\n",
      "Running RLO ensemble. Pool = 20. K-fold = 5\n",
      "Running RLO ensemble. Pool = 30. K-fold = 5\n",
      "Running RLO ensemble. Pool = 40. K-fold = 5\n",
      "Running RLO ensemble. Pool = 50. K-fold = 5\n",
      "Running RLO ensemble. Pool = 60. K-fold = 5\n",
      "Running RLO ensemble. Pool = 70. K-fold = 5\n",
      "Running RLO ensemble. Pool = 80. K-fold = 5\n",
      "Running RLO ensemble. Pool = 90. K-fold = 5\n",
      "Running RLO ensemble. Pool = 100. K-fold = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RLO': {'10': [{'execution': 0,\n",
       "    'ensemble_fit_time': 6.429979562759399,\n",
       "    'oracle_fit_time': 4.9747233390808105,\n",
       "    'oracle_score': 0.9760814249363867},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 6.505911588668823,\n",
       "    'oracle_fit_time': 5.109114170074463,\n",
       "    'oracle_score': 0.9776081424936387},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 6.715482234954834,\n",
       "    'oracle_fit_time': 5.223706007003784,\n",
       "    'oracle_score': 0.9684317718940937},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 6.602667570114136,\n",
       "    'oracle_fit_time': 5.207964658737183,\n",
       "    'oracle_score': 0.9765784114052953},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 6.617240905761719,\n",
       "    'oracle_fit_time': 5.138136625289917,\n",
       "    'oracle_score': 0.9745417515274949}],\n",
       "  '20': [{'execution': 0,\n",
       "    'ensemble_fit_time': 12.895809173583984,\n",
       "    'oracle_fit_time': 10.108913660049438,\n",
       "    'oracle_score': 0.9842239185750636},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 13.47414255142212,\n",
       "    'oracle_fit_time': 10.760666370391846,\n",
       "    'oracle_score': 0.9852417302798983},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 13.601337671279907,\n",
       "    'oracle_fit_time': 10.890922784805298,\n",
       "    'oracle_score': 0.9826883910386965},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 14.90283989906311,\n",
       "    'oracle_fit_time': 11.211121082305908,\n",
       "    'oracle_score': 0.9882892057026477},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 14.419621229171753,\n",
       "    'oracle_fit_time': 12.169788599014282,\n",
       "    'oracle_score': 0.9877800407331976}],\n",
       "  '30': [{'execution': 0,\n",
       "    'ensemble_fit_time': 24.21958613395691,\n",
       "    'oracle_fit_time': 17.946600914001465,\n",
       "    'oracle_score': 0.9888040712468193},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 23.445316314697266,\n",
       "    'oracle_fit_time': 17.525485515594482,\n",
       "    'oracle_score': 0.9928753180661578},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 24.034122943878174,\n",
       "    'oracle_fit_time': 16.564403772354126,\n",
       "    'oracle_score': 0.9852342158859471},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 21.648848295211792,\n",
       "    'oracle_fit_time': 16.13663387298584,\n",
       "    'oracle_score': 0.9893075356415478},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 20.736069679260254,\n",
       "    'oracle_fit_time': 17.34001660346985,\n",
       "    'oracle_score': 0.9872708757637475}],\n",
       "  '40': [{'execution': 0,\n",
       "    'ensemble_fit_time': 28.59697413444519,\n",
       "    'oracle_fit_time': 21.785163640975952,\n",
       "    'oracle_score': 0.9877862595419847},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 27.78513503074646,\n",
       "    'oracle_fit_time': 22.063228607177734,\n",
       "    'oracle_score': 0.9933842239185751},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 29.2039692401886,\n",
       "    'oracle_fit_time': 21.998453617095947,\n",
       "    'oracle_score': 0.9898167006109979},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 28.044813632965088,\n",
       "    'oracle_fit_time': 21.840026378631592,\n",
       "    'oracle_score': 0.9898167006109979},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 28.55178737640381,\n",
       "    'oracle_fit_time': 22.504776000976562,\n",
       "    'oracle_score': 0.9893075356415478}],\n",
       "  '50': [{'execution': 0,\n",
       "    'ensemble_fit_time': 37.09014177322388,\n",
       "    'oracle_fit_time': 28.4844810962677,\n",
       "    'oracle_score': 0.9918575063613232},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 34.9354510307312,\n",
       "    'oracle_fit_time': 27.52798342704773,\n",
       "    'oracle_score': 0.9954198473282443},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 35.242921352386475,\n",
       "    'oracle_fit_time': 27.7275869846344,\n",
       "    'oracle_score': 0.9877800407331976},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 34.726001024246216,\n",
       "    'oracle_fit_time': 29.433393716812134,\n",
       "    'oracle_score': 0.9913441955193483},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 39.84620928764343,\n",
       "    'oracle_fit_time': 31.14616560935974,\n",
       "    'oracle_score': 0.9923625254582484}],\n",
       "  '60': [{'execution': 0,\n",
       "    'ensemble_fit_time': 47.1455500125885,\n",
       "    'oracle_fit_time': 36.810750246047974,\n",
       "    'oracle_score': 0.9944020356234097},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 47.873762369155884,\n",
       "    'oracle_fit_time': 36.10055494308472,\n",
       "    'oracle_score': 0.9969465648854962},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 48.803728342056274,\n",
       "    'oracle_fit_time': 36.89420294761658,\n",
       "    'oracle_score': 0.9908350305498982},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 47.89682054519653,\n",
       "    'oracle_fit_time': 36.348787784576416,\n",
       "    'oracle_score': 0.995417515274949},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 48.676727533340454,\n",
       "    'oracle_fit_time': 35.49641251564026,\n",
       "    'oracle_score': 0.9913441955193483}],\n",
       "  '70': [{'execution': 0,\n",
       "    'ensemble_fit_time': 56.81095576286316,\n",
       "    'oracle_fit_time': 43.38609290122986,\n",
       "    'oracle_score': 0.9949109414758269},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 56.307859659194946,\n",
       "    'oracle_fit_time': 39.8648042678833,\n",
       "    'oracle_score': 0.9964376590330789},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 56.030895471572876,\n",
       "    'oracle_fit_time': 42.364596128463745,\n",
       "    'oracle_score': 0.9908350305498982},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 55.38998198509216,\n",
       "    'oracle_fit_time': 42.317769050598145,\n",
       "    'oracle_score': 0.994908350305499},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 56.180426597595215,\n",
       "    'oracle_fit_time': 42.01752328872681,\n",
       "    'oracle_score': 0.9938900203665988}],\n",
       "  '80': [{'execution': 0,\n",
       "    'ensemble_fit_time': 63.66523051261902,\n",
       "    'oracle_fit_time': 46.85692644119263,\n",
       "    'oracle_score': 0.9938931297709923},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 62.89453101158142,\n",
       "    'oracle_fit_time': 50.247228384017944,\n",
       "    'oracle_score': 0.9984732824427481},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 62.02988409996033,\n",
       "    'oracle_fit_time': 44.861817836761475,\n",
       "    'oracle_score': 0.9903258655804481},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 55.67132902145386,\n",
       "    'oracle_fit_time': 44.67143368721008,\n",
       "    'oracle_score': 0.9959266802443992},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 56.25368118286133,\n",
       "    'oracle_fit_time': 44.61335301399231,\n",
       "    'oracle_score': 0.994908350305499}],\n",
       "  '90': [{'execution': 0,\n",
       "    'ensemble_fit_time': 63.65164804458618,\n",
       "    'oracle_fit_time': 49.62544083595276,\n",
       "    'oracle_score': 0.9954198473282443},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 64.57703638076782,\n",
       "    'oracle_fit_time': 49.03702259063721,\n",
       "    'oracle_score': 0.9979643765903308},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 67.39438676834106,\n",
       "    'oracle_fit_time': 54.81077456474304,\n",
       "    'oracle_score': 0.9959266802443992},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 71.97340798377991,\n",
       "    'oracle_fit_time': 52.37046766281128,\n",
       "    'oracle_score': 0.9959266802443992},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 72.06678795814514,\n",
       "    'oracle_fit_time': 53.14098787307739,\n",
       "    'oracle_score': 0.9969450101832994}],\n",
       "  '100': [{'execution': 0,\n",
       "    'ensemble_fit_time': 80.04102659225464,\n",
       "    'oracle_fit_time': 60.1125705242157,\n",
       "    'oracle_score': 0.9959287531806615},\n",
       "   {'execution': 1,\n",
       "    'ensemble_fit_time': 78.3699722290039,\n",
       "    'oracle_fit_time': 63.119866371154785,\n",
       "    'oracle_score': 0.9979643765903308},\n",
       "   {'execution': 2,\n",
       "    'ensemble_fit_time': 80.15623331069946,\n",
       "    'oracle_fit_time': 57.72579026222229,\n",
       "    'oracle_score': 0.994908350305499},\n",
       "   {'execution': 3,\n",
       "    'ensemble_fit_time': 74.07459878921509,\n",
       "    'oracle_fit_time': 60.39561653137207,\n",
       "    'oracle_score': 0.9959266802443992},\n",
       "   {'execution': 4,\n",
       "    'ensemble_fit_time': 75.02375268936157,\n",
       "    'oracle_fit_time': 59.56338906288147,\n",
       "    'oracle_score': 0.9959266802443992}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_insurance = insurance_data.iloc[:,0:len(insurance_columns)-1] # separacao de atributos\n",
    "y_insurance = insurance_data.iloc[:,len(insurance_columns)-1] # separacao de classes\n",
    "\n",
    "insurance_score = {}\n",
    "ensemble_method = \"RLO\"\n",
    "insurance_score[ensemble_method] = {}\n",
    "for n_pool in n_pools:\n",
    "    result = run_ensemble_method(X_insurance, y_insurance, ensemble_method, n_pool, 5)\n",
    "    insurance_score[ensemble_method][str(n_pool)] = result\n",
    "insurance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SGH ensemble. Pool = 10. K-fold = 5\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      ".estimators_ [SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None)]\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      ".estimators_ [SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None)]\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".estimators_ [SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None)]\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      ".estimators_ [SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "c:\\users\\barre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      "idx_class_1 0 idx_class_2 1\n",
      ".estimators_ [SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None), SGDClassifier(eta0=1e-17, learning_rate='constant', loss='perceptron',\n",
      "              max_iter=1, penalty=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'execution': 0,\n",
       "  'ensemble_fit_time': 0.030007123947143555,\n",
       "  'oracle_fit_time': 0.11102485656738281,\n",
       "  'oracle_score': 0.9994910941475827},\n",
       " {'execution': 1,\n",
       "  'ensemble_fit_time': 0.04501008987426758,\n",
       "  'oracle_fit_time': 0.11102509498596191,\n",
       "  'oracle_score': 1.0},\n",
       " {'execution': 2,\n",
       "  'ensemble_fit_time': 0.044010162353515625,\n",
       "  'oracle_fit_time': 0.11002469062805176,\n",
       "  'oracle_score': 1.0},\n",
       " {'execution': 3,\n",
       "  'ensemble_fit_time': 0.046010494232177734,\n",
       "  'oracle_fit_time': 0.11402535438537598,\n",
       "  'oracle_score': 1.0},\n",
       " {'execution': 4,\n",
       "  'ensemble_fit_time': 0.04300975799560547,\n",
       "  'oracle_fit_time': 0.11002445220947266,\n",
       "  'oracle_score': 1.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_insurance = insurance_data.iloc[:,0:len(insurance_columns)-1] # separacao de atributos\n",
    "y_insurance = insurance_data.iloc[:,len(insurance_columns)-1] # separacao de classes\n",
    "\n",
    "result = run_ensemble_method(X_insurance, y_insurance, \"SGH\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
